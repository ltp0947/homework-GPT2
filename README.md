# homework-GPT2
1.Description
利用开源的中文GPT2模型在自己的数据集上进行训练。GTP2来源：https://github.com/lvfinn/chinese-GPT2-start-from-zero；数据集：《凡人修仙传》的.txt文本；目标：对给定的一句开头，续写十句话以上的文本

2.Modification
